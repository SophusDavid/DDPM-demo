{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/gs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 使用MNIST数据集\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, einsum\n",
    "# 数据集\n",
    "train_set=torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "test_set=torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "batch_size = 512\n",
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=8,drop_last=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=False,drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图\n",
    "def plot_images(images,labels):\n",
    "    n_images=len(images)\n",
    "    rows=int(np.sqrt(n_images))\n",
    "    cols=int(np.sqrt(n_images))\n",
    "    fig=plt.figure()\n",
    "    for i in range(rows*cols):\n",
    "        ax=fig.add_subplot(rows,cols,i+1)\n",
    "        ax.imshow(images[i].view(28,28).cpu().numpy(),cmap='bone')\n",
    "        ax.set_title(labels[i].item())\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "images,labels=next(iter(train_loader))\n",
    "# plot_images(images,labels)\n",
    "# 如果val非None则返回val，否则(如果d为函数则返回d(),否则返回d)\n",
    "from inspect import isfunction # inspect模块https://www.cnblogs.com/yaohong/p/8874154.html主要提供了四种用处：1.对是否是模块、框架、函数进行类型检查 2.获取源码 3.获取类或者函数的参数信息 4.解析堆栈\n",
    "from functools import partial \n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加噪测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=1000\n",
    "import numpy as np\n",
    "# beta from 0.0001 to 0.02 in 1000 steps \n",
    "# exp from log(0.0001) to log(0.02) in 1000 steps\n",
    "\n",
    "beta=torch.tensor(np.linspace(0.0001,0.02,t))\n",
    "alpha=1-beta\n",
    "# alpha 累乘\n",
    "alpha_multiply=torch.cumprod(alpha,dim=-1)\n",
    "\n",
    "# 创建和图片一样shape高斯噪声\n",
    "noise=torch.randn_like(images)*torch.sqrt(1-alpha_multiply[-1])+torch.sqrt(alpha_multiply[-1])*images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_images(noise,labels)\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "# 上采样\n",
    "def Upsample(dim):\n",
    "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "# 下采样\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
    "import math\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time.unsqueeze(1) * embeddings.unsqueeze(0)\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PE测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emd=SinusoidalPositionEmbeddings(28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.full((batch_size,),1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emd(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups = 8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n",
    "        self.norm = nn.GroupNorm(groups, dim_out) #GN归一化 https://zhuanlan.zhihu.com/p/177853578\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.proj(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if scale_shift is not None:\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\"https://arxiv.org/abs/2201.03545\"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n",
    "        super().__init__()\n",
    "        # 如果time_emb_dim存在则有mlp层\n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out * mult, 3, padding=1),\n",
    "            nn.GELU(), # Gaussian Error Linear Unit\n",
    "            nn.GroupNorm(1, dim_out * mult),\n",
    "            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        if self.mlp is not None and time_emb is not None:\n",
    "            assert time_emb is not None, \"time embedding must be passed in\"\n",
    "            condition = self.mlp(time_emb)\n",
    "            h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
    "\n",
    "        h = self.net(h)\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先norm后fn\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = nn.GroupNorm(1, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)# qkv为一个元组，其中每一个元素的大小为torch.Size([b, hidden_dim, h, w])\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        ) # qkv中每个元素从torch.Size([b, hidden_dim, h, w])变为torch.Size([b, heads, dim_head, h*w])\n",
    "        q = q * self.scale # q扩大dim_head**-0.5倍\n",
    "\n",
    "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k) # sim有torch.Size([b, heads, h*w, h*w])\n",
    "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
    "        attn = sim.softmax(dim=-1) # attn有torch.Size([b, heads, h*w, h*w])\n",
    "\n",
    "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v) # [b, heads, h*w, h*w]和[b, heads, dim_head, h*w] 得 out为[b, heads, h*w, dim_head]\n",
    "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w) # 得out为[b, hidden_dim, h, w]\n",
    "        return self.to_out(out) # 得 [b, dim, h, w]\n",
    "\n",
    "# 和class Attention几乎一致\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4, dim_head=32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head**-0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1), \n",
    "                                    nn.GroupNorm(1, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1) \n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
    "        )\n",
    "\n",
    "        q = q.softmax(dim=-2)\n",
    "        k = k.softmax(dim=-1)\n",
    "\n",
    "        q = q * self.scale\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim, # 下例中，dim=image_size=28\n",
    "        init_dim=None,# 默认为None，最终取dim // 3 * 2\n",
    "        out_dim=None, # 默认为None，最终取channels\n",
    "        dim_mults=(1,2,4,8),\n",
    "        channels=3, # 通道数默认为3\n",
    "        with_time_emb=True, # 是否使用embeddings\n",
    "        resnet_block_groups=8, # 如果使用ResnetBlock，groups=resnet_block_groups\n",
    "        use_convnext=True, # 是True使用ConvNextBlock，是Flase使用ResnetBlock\n",
    "        convnext_mult=2, # 如果使用ConvNextBlock，mult=convnext_mult\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        \n",
    "        init_dim = default(init_dim, dim // 3 * 2)\n",
    "        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)\n",
    "        \n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)] # 从头到尾dim组成的列表\n",
    "        in_out = list(zip(dims[:-1], dims[1:])) # dim对组成的列表\n",
    "        # 使用ConvNextBlock或ResnetBlock\n",
    "        if use_convnext:\n",
    "            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n",
    "        # else:\n",
    "        #     block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
    "            \n",
    "        # time embeddings\n",
    "        if with_time_emb:\n",
    "            time_dim = dim * 4\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPositionEmbeddings(dim),\n",
    "                nn.Linear(dim, time_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(time_dim, time_dim),\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "            \n",
    "        # layers\n",
    "        self.downs = nn.ModuleList([]) # 初始化下采样网络列表\n",
    "        self.ups = nn.ModuleList([]) # 初始化上采样网络列表\n",
    "        num_resolutions = len(in_out) # dim对组成的列表的长度\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1) # 是否到了最后一对\n",
    "            \n",
    "            self.downs.append(\n",
    "                nn.ModuleList(\n",
    "                [\n",
    "                    block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
    "                    block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
    "                    Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                    Downsample(dim_out) if not is_last else nn.Identity(),\n",
    "                ]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim,time_emb_dim=time_dim)\n",
    "        \n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
    "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
    "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.Sequential(\n",
    "            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, time):\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
    "\n",
    "        h = []\n",
    "\n",
    "        # downsample\n",
    "        for block1, block2, attn, downsample in self.downs:\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        # bottleneck\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        # upsample\n",
    "        for block1, block2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = block1(x, t)\n",
    "            x = block2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "channels = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet(\n",
    "    dim=image_size,\n",
    "    channels = channels,\n",
    "    dim_mults=(1,2,4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleGaussianDiffusion(nn.Module):\n",
    "    def __init__(self,T,denoise_net,device):\n",
    "        super(SimpleGaussianDiffusion,self).__init__()\n",
    "        self.beta=torch.tensor(np.linspace(0.0001,0.02,T)).repeat(batch_size,1).to(device)\n",
    "        # print(self.beta.shape)\n",
    "        self.device=device\n",
    "        self.T=T\n",
    "        self.denoise_net=denoise_net\n",
    "        self.alpha=1-self.beta\n",
    "        # positional embedding about t\n",
    "        # self.t_emb=nn.Embedding(T,128)\n",
    "\n",
    "        # alpha 累乘\n",
    "        self.alpha_multiply=torch.cumprod(self.alpha,dim=-1)\n",
    "        print(self.alpha_multiply.shape)\n",
    "        self.alpha_multiply_prev=F.pad(self.alpha_multiply[...,:-1],(1,0),value=1.)\n",
    "        print(self.alpha_multiply_prev.shape)\n",
    "        self.posterior_variance = self.beta * (1. - self.alpha_multiply_prev) / (1. - self.alpha_multiply)\n",
    "        \n",
    "        print(self.posterior_variance.shape)\n",
    "    def forward_add_noise(self,images,t,eps=None):\n",
    "        # 获取alpha\n",
    "        if eps is  None:\n",
    "            eps=torch.randn_like(images)\n",
    "        alpha_multiply=torch.gather(self.alpha_multiply,dim=1,index=t.unsqueeze(1)).float()\n",
    "        # print(alpha_multiply.shape)\n",
    "        # 创建和图片一样shape高斯噪声\n",
    "        noise=eps*torch.sqrt(1-alpha_multiply).unsqueeze(1).unsqueeze(1) +torch.sqrt(alpha_multiply).unsqueeze(1).unsqueeze(1)*images\n",
    "        return noise,eps\n",
    "    \n",
    "    def forward(self,x,t,eps=None):\n",
    "        # t is a scalar\n",
    "        # x shape is [batch_size,H,W,C]\n",
    "        batch_size,C,H,W=x.shape\n",
    "        # print(x.shape)\n",
    "        # x=x.permute(0,3,1,2)\n",
    "        # embedding t to [batch_size,1,1,128]\n",
    "        # pe_t=pe_t.unsqueeze(0).unsqueeze(2).unsqueeze(2).expand(batch_size,128,H,W)\n",
    "        noise,noise_std=self.forward_add_noise(x,t,eps)\n",
    "        # print(noise.shape)\n",
    "        # print(pe_t.shape)\n",
    "        # noise=torch.cat([noise,pe_t],dim=1)\n",
    "        # predited noise\n",
    "        pred_noise=self.denoise_net(noise,t)\n",
    "\n",
    "        return pred_noise\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self,x,t):\n",
    "        # print(t.shape)\n",
    "        B=x.shape[0]\n",
    "        t_=torch.full((B,),t).long().cuda()\n",
    "        z=torch.randn_like(x)\n",
    "        beta=torch.gather(self.beta,dim=1,index=t_.unsqueeze(1)).unsqueeze(1).unsqueeze(1).float()\n",
    "        alpha=torch.gather(self.alpha,dim=1,index=t_.unsqueeze(1)).unsqueeze(1).unsqueeze(1).float()\n",
    "        alpha_multiply=torch.gather(self.alpha_multiply,dim=1,index=t_.unsqueeze(1)).unsqueeze(1).unsqueeze(1).float()\n",
    "        # print(alpha_multiply.shape,alpha.shape,beta.shape)\n",
    "        # print(x.shape)\n",
    "        # print(self.denoise_net(x,t).shape)\n",
    "        x_t_1=1/(torch.sqrt(alpha))*(x-(beta/torch.sqrt(1-alpha_multiply))*self.denoise_net(x,t_))\n",
    "        # t==0的地方，beta=0\n",
    "        posterior_variance_t=torch.gather(self.posterior_variance,dim=1,index=t_.unsqueeze(1)).unsqueeze(1).unsqueeze(1).float()\n",
    "        if t==0:\n",
    "        \n",
    "            return x_t_1\n",
    "        else:\n",
    "            return x_t_1+ torch.sqrt(beta) *z\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self,x):\n",
    "        for i in reversed(range(0,self.T)):\n",
    "            x=self.p_sample(x,i)\n",
    "        return x\n",
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1000])\n",
      "torch.Size([512, 1000])\n",
      "torch.Size([512, 1000])\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "diffusion=SimpleGaussianDiffusion(T=1000,denoise_net=model.to(device)\n",
    ",device=device).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.MSELoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=1e-3)\n",
    "# 训练\n",
    "eps=None\n",
    "for epoch in range(10):\n",
    "    for images,labels in train_loader:\n",
    "        images=images.to(device)\n",
    "        labels=labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(0, 1000, (batch_size,), device=device).long()\n",
    "        # print(t[0])\n",
    "        if eps is None:\n",
    "            eps=torch.randn_like(images)\n",
    "        pred_noise=diffusion(images,t.to(device),eps)\n",
    "        l=loss(pred_noise,eps)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch {epoch},loss={l.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.randn(16,1,28,28).to(device)\n",
    "t=torch.tensor([0]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_sample=diffusion.p_sample_loop(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(re_sample,torch.zeros(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 要点：\n",
    "* 去噪要逆向\n",
    "* 训练时，噪声需要固定（？\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
